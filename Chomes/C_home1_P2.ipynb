{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YD2iqk891zff"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pregunta 1\n",
        "\n",
        "## Parte A\n",
        "### Lógica\n",
        "\n",
        "Se busca determinar el valor del coeficiente cc en la expansión de Taylor, utilizando un método con convergencia cuadrática. Para esto, se propone el uso del método de Newton, ya que se indica que la raíz tiene multiplicidad 1.\n",
        "\n",
        "Esto implica usar el método de Newton ó Newton modificado, pero como m=1, entonces solo usaremos newton.\n",
        "\n",
        "Primero necesitamos obtener lo que pide este método.\n",
        "\n",
        "1. La función f(x) y f'(x)\n",
        "2. El punto inicial (o initial guess), para esta pregunta, el punto inicial será el punto entre $x$ y $x0$\n",
        "\n",
        "La forma en la que está la función f(x) que nos dan no es muy amigable, por lo que podríamos cambiarla a una forma equivalente.\n",
        "\n",
        "$f(x) = f(x_0) + f'(x_0)(x-x_0) + \\frac{f''(x_0)}{2!}(x-x_0)^2+ ... + \\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k + \\frac{f^{(k+1)}(c)}{(k+1)!}(x-x_0)^{k+1}$\n",
        "\n",
        "Para que sea más bonito, cambiemos todo lo que está a la izquierda de $\\frac{f^{(k+1)}(c)}{(k+1)!}(x-x_0)^{k+1}$ a $T_k(x)$\n",
        "\n",
        "Es decir: $f(x_0) + f'(x_0)(x-x_0) + \\frac{f''(x_0)}{2!}(x-x_0)^2+ ... + \\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k = T_k(x)$\n",
        "\n",
        "Y queda como: $f(x) = T_k(x) + \\frac{f^{(k+1)}(c)}{(k+1)!}(x-x_0)^{k+1}$, de esta forma podemos poner todo nuestro enfoque en c. \n",
        "\n",
        "Recordando lo que conocemos, podemos saber que $f(x)$ y $T_k(x)$ son un numero constante, ya que conocemos a $x$ y a $x_0$ y las k derivadas de f(x) son obtenibles computacionalmente. \n",
        "\n",
        "Luego podemos mover $T_k(x)$ al otro lado de la ecuación y queda: $\\frac{f^{(k+1)}(c)}{(k+1)!}(x-x_0)^{k+1} = f(x) -T_k(x)$\n",
        "\n",
        "Moviendo el resto de las variables quedamos con $f^{(k+1)}(c) = \\frac{(f(x) -T_k(x))(k+1)!}{(x-x_0)^{k+1}}$\n",
        "\n",
        "Dejemos a $\\frac{(f(x) -T_k(x))(k+1)!}{(x-x_0)^{k+1}} = ϕ(c)$ por simplicidad\n",
        "\n",
        "Con esto, podemos obtener $f^{(k+1)}(c) = ϕ(c)$ y al pasarl $ϕ(c)$ a la izquierda quedamos con $G(c) := f^{(k+1)}(c) - ϕ(c) = 0$ \n",
        "\n",
        "\n",
        "\n",
        "Y esta será función con la que podríamos iterar usando el método de Newton.\n",
        "\n",
        "### Algoritmo\n",
        "Para aplicar el algoritmo, si o si se necesita la derivada de la función con la cual iteraremos, por lo que voy a asumir que se puede obtener.\n",
        "\n",
        "Luego $G'(c) = f^{(k+2)}(c)$ (el $ϕ(c)$ se elimina ya que es una constante respecto a c).\n",
        "\n",
        "Con esto podemos tener la siguiente iteración de Newton.\n",
        "\n",
        "$c_{i+1} = c_i - \\frac{f^{(k+1)}(c) - ϕ(c)}{f^{(k+2)}(c)}$\n",
        "\n",
        "Finalmente, el orden de acciones a seguir es:\n",
        "1. Obtener f(x), ya que conocemos f(x) y x.\n",
        "2. Evaluar el polinomio hasta k, es decir, obtener las derivadas hasta k y luego evaluar con $x$ e $x_0$, es decir, obtener $T_k(c)$\n",
        "3. Calcular la constante $ϕ(c)$, esta se calcula después de obtener las derivadas ya que su valor posiblemente cambie con el tamaño de k y por ende la precisón de la aproximación.\n",
        "4. Definir $G(c) := f^{(k+1)}(c) - ϕ(c) = 0$\n",
        "5. Aplicar Newton hasta que se llegue a una tolerancia o numero de iteraciones.\n",
        "6. Valor de c debería ser la raíz de $G(c)$, lo cual obtenemos al finalizar las iteraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte B\n",
        "Se implementa el algoritmo usando las funciones dadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "input :\n",
        "x : (float) value of $x$.\n",
        "x0 : (float) value of $x_0$\n",
        "k : (integer) This defines the number of terms to be used, which is $k+1$.\n",
        "output:\n",
        "c : (float) the estimated value for $c$.\n",
        "'''\n",
        "def find_c(x,x0,k):\n",
        "# Your own code.\n",
        "    dx= x-x0\n",
        "\n",
        "    #paso 1\n",
        "    fx = k_derivatives_of_f(x,0) #no la tengo y no la voy a definir :)\n",
        "\n",
        "    #paso 2\n",
        "    vector_k = np.arange(k+1) #de 0 a k\n",
        "    derivadas = k_derivatives_of_f(x0,vector_k) #derivadas en x0\n",
        "    powers = np.power(dx, vector_k) #potencias de dx\n",
        "    factoriales = my_factorial(vector_k) #factoriales de k   \n",
        "    Tk = np.dot(derivadas / factoriales, powers)\n",
        "\n",
        "    #paso 3\n",
        "    phi = (my_factorial(k+1) * (fx - Tk)) / np.power(dx, k+1)\n",
        "\n",
        "    #paso 4, newton\n",
        "    #como dijimos antes, el punto medio entre x0 y x será el initial guess\n",
        "    c_i = (x0 + x) / 2\n",
        "    #necesitamos a G(c_i) y G'(c_i)\n",
        "    def G(c):\n",
        "        return k_derivative_of_f(c, k+1) - phi\n",
        "    def Gp(c):\n",
        "        return k_derivative_of_f(c, k+2)\n",
        "\n",
        "    c = Newton1D(G,Gp,c_i,m=1)\n",
        "    \n",
        "    return c\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU7zpC_P1KQw"
      },
      "source": [
        "# Pregunta 2\n",
        "## Parte A\n",
        "\n",
        "Nos dan los vectores:\n",
        "\n",
        "$x = [2^{-800},2^{-800}],\n",
        "\\newline\n",
        "y = [2^{-700},2^{-700}].$\n",
        "\n",
        "Hacemos un ruteo de la función dada considerando double precision.\n",
        "\n",
        "### Ruteo\n",
        "\n",
        "El producto punto correspondiente es: $2^{-800} * 2^{-700} + 2^{-800} * 2^{-700}$ lo cual es $2^{-1500} + 2^{-1500} = 2^{-1499}$\n",
        "\n",
        "Pero, como estamos con precisión doble conocemos que el valor minimo posible es $2^{-1074}$ (la explicación es muy larga, pero es tan simple como pensar que la precisión limitada y con un exponente y mantisa de ciertos valores, el valor minimo almacenado debido al uso de los bits es tambien limitado a un tamaño, y con precisión doble es $2^{-1074}$) y por ende $2^{-1500}$ se anula y queda 0 por lo que el producto punto es 0.\n",
        "\n",
        "Luego se calcula n_x usando my_norm_2(x):\n",
        "\n",
        "Se obtiene max_abs_value, en este caso es $max\\_abs\\_value = 2^{-800}$\n",
        "\n",
        "x_tilde es: $x_{tilde} = \\frac{[2^{-800},2^{-800}]}{2^{-800}}$\n",
        "\n",
        "x_tilde_norm es la norma 2 del vector x_tilde (puedo observar que se normaliza el vector para evitar anular todo con la doble precisión): $x\\_tilde\\_norm = \\sqrt{1^2 + 1^2} = \\sqrt{2}$\n",
        "\n",
        "luego la norma2 es $norm_2 = 2^{-800} * \\sqrt{2}$\n",
        "\n",
        "Volviendo a la función anterior, quedamos con n_x igual a $2^{-800} * \\sqrt{2}$\n",
        "\n",
        "Pero el siguiente paso es dot/n_x como sabemos que dot es 0 entonces out queda como 0\n",
        "\n",
        "El siguiente paso es calcular n_y, pero como se hará otra división igual a la anterior el valor seguirá siendo 0.\n",
        "\n",
        "Finalmente se retorna 0 (podría decirse que los vectores son perpendiculares, pero claramente no es así)\n",
        "\n",
        "\n",
        "## Parte B\n",
        "### Parte A (de la B)\n",
        "\n",
        "#### Lógica\n",
        "Como vimos antes, el problema radica en la forma en que se calcula el producto punto. Pero si normalizamos los vectores x e y antes de calcular el producto punto, como se hace en my_norm_2, podremos evitar la anulación que se produce.\n",
        "\n",
        "Tengamos la similitud del coseno: \n",
        "$ \\frac{\\langle x,y \\rangle}{ ||x||_2 ||y||_2}$\n",
        "\n",
        "Cambiemos los valores de $||x||_2$ y de $||y||_2$ a uno equivalente, como visto en la función my_norm_2 se retorna norm_2 = max_abs_value*x_tilde_norm, que es la norma del vector multiplicado por el valor máximo de la función y visto en el enunciado: $||x||_2 = α||\\frac{x}{α}||$ con α el valor máximo del vector x y $||y||_2 = β||\\frac{y}{β}||$ con β el valor máximo del vector y.\n",
        "\n",
        "Luego tendemos esto:\n",
        "$ \\frac{\\langle x,y \\rangle}{ α||\\frac{x}{α}|| β||\\frac{y}{β}||}$\n",
        "\n",
        "Podemos usar los máximos valores de los vectores para normalizar a x e y antes de calcular el producto punto y evitar la anulación!\n",
        "\n",
        "#### Algoritmo\n",
        "Sería muy similar al algoritmo que nos dieron en el enunciado, solo que habrán unos pasos extra como normalizar a x e y, luego tendremos que agregar los máximos para no perder la equivalencia.\n",
        "\n",
        "1. Escalar a X y a Y\n",
        "2. Calcular el producto punto de X_n e Y_n\n",
        "3. Calcular la norma 2 de X e Y usando my_norm_2\n",
        "4. Hacer las divisiones para obtener la similitud del coseno\n",
        "\n",
        "### Parte B (de la B)\n",
        "\n",
        "Primero normalizamos \n",
        "$x_n = \\frac{[2^{-800},2^{-800}]}{2^{-800}} = [1, 1]$\n",
        "$y_n = \\frac{[2^{-700},2^{-700}]}{2^{-700}} = [1, 1]$\n",
        "El producto punto correspondiente es: $dot = [1,1]*[1,1] = 1+1 = 2$\n",
        "\n",
        "Luego se calcula n_x usando my_norm_2(x):\n",
        "\n",
        "Se obtiene max_abs_value, en este caso es $max\\_abs\\_value = 2^{-800}$\n",
        "\n",
        "x_tilde es: $x_{tilde} = \\frac{[2^{-800},2^{-800}]}{2^{-800}}$\n",
        "\n",
        "x_tilde_norm es la norma 2 del vector x_tilde (puedo observar que se normaliza el vector para evitar anular todo con la doble precisión): $x\\_tilde\\_norm = \\sqrt{1^2 + 1^2} = \\sqrt{2}$\n",
        "\n",
        "luego la norma2 es $norm_2 = 2^{-800} * \\sqrt{2}$\n",
        "\n",
        "Volviendo a la función anterior, quedamos con n_x igual a $2^{-800} * \\sqrt{2}$\n",
        "\n",
        "Luego, dot/n_x es $\\frac{2}{2^{-800} * \\sqrt{2}}$\n",
        "\n",
        "Como antes normalizamos a x, debemos multiplicarle el valor máximo de x a esta expresión para que quede equivalente.\n",
        "\n",
        "$out = \\frac{2*2^{-800}}{2^{-800} * \\sqrt{2}}$ y se simplifica:\n",
        "\n",
        "$out = \\frac{2}{\\sqrt{2}}$\n",
        "\n",
        "El siguiente paso es calcular n_y, el valor es similar al de n_x.\n",
        "\n",
        "$n_y = 2^{-700} * \\sqrt{2}$\n",
        "\n",
        "Lo que sigue es cs = out/n_y\n",
        "\n",
        "$cs = \\frac{\\frac{2}{\\sqrt{2}}}{2^{-700} * \\sqrt{2}}$\n",
        "\n",
        "Igual que antes, como se normaliza Y, tenemos que multiplicar su valor máximo.\n",
        "\n",
        "$cs = \\frac{\\frac{2}{\\sqrt{2}}*2^{-700}}{2^{-700} * \\sqrt{2}} = \\frac{2}{\\sqrt{2}*\\sqrt{2}} = \\frac{2}{2} = 1$ \n",
        "\n",
        "Finalmente se retorna 1, lo que es correcto ya que los vectores son paralelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte C\n",
        "Se implementa la función descrita"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IW2oepQO1HQP"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "input:\n",
        "x : (ndarray) Input vector 'x'.\n",
        "output:\n",
        "norm_2 : (float) norm-2 of the vector 'x'\n",
        "'''\n",
        "def my_norm_2(x):\n",
        "    # Getting the max absolute value\n",
        "    max_abs_value = np.max(np.abs(x))\n",
        "\n",
        "    # Scaling the vector\n",
        "    x_tilde = x/max_abs_value\n",
        "\n",
        "    # Computing the 2-norm of the scaled vector\n",
        "    x_tilde_norm = np.linalg.norm(x_tilde)\n",
        "\n",
        "    # Computing the actual 2-norm of ’x’\n",
        "    norm_2 = max_abs_value*x_tilde_norm\n",
        "\n",
        "    # Return the computed norm-2\n",
        "    return norm_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity_v1(x,y):\n",
        "    # Primero normalizamos los vectores\n",
        "    x_max = np.max(np.abs(x))\n",
        "    x_n = x/x_max\n",
        "    y_max = np.max(np.abs(y))\n",
        "    y_n = y/y_max\n",
        "    # Producto punto entre los vectores normalizados\n",
        "    dot_product = np.dot(x_n,y_n)\n",
        "\n",
        "    # Computing the 2-norm of x\n",
        "    n_x = my_norm_2(x_n)\n",
        "    # Computing the first division y multiplicamos para que el resultado sea el mismo\n",
        "    out = dot_product/n_x\n",
        "    # Computing the 2-norm of y\n",
        "    n_y = my_norm_2(y_n)\n",
        "    # Computing the second division y multiplicamos para que el resultado sea el mismo\n",
        "    cs = out/n_y\n",
        "    # Returning the computed cosine similarity\n",
        "    return cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9999999999999999"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#probemos \n",
        "x = np.array([np.power(2,-800.),np.power(2,-800.)])\n",
        "y = np.array([np.power(2,-700.),np.power(2,-700.)])\n",
        "cosine_similarity_v1(x,y)\n",
        "#close enough"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L_2Mdf_51vvQ",
        "FspKk3_j2lsh"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
